import asyncio
import aiofiles
import logging
import requests
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import hashlib
import json
import time
import re
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
from fastapi import FastAPI, File, UploadFile, HTTPException, Request, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import GPUtil
import psutil
import subprocess
import yt_dlp
import sqlite3
import threading
from queue import Queue
import ast
import urllib.parse
from duckduckgo_search import DDGS
from bs4 import BeautifulSoup
import wikipedia
import base64
import pytz

# ==================== NEW SYSTEMS ====================
from test_system import test_system
from backup_system import backup_system
from model_hierarchy import model_hierarchy

# ==================== LOGGING SETUP (FIXED!) ====================
log_dir = Path("/app/logs")
log_dir.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'ii_agent.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MODEL_TIMEOUT = 300
MAX_FILE_SIZE = 10 * 1024 * 1024
CHROMA_DB_PATH = "/app/data/chroma_db"
BACKUP_DIR = Path("/app/data/backups")
BACKUP_DIR.mkdir(parents=True, exist_ok=True)
OLLAMA_API_URL = "http://host.docker.internal:11434"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
try:
    gpus = GPUtil.getGPUs()
    HAS_GPU = len(gpus) > 0
    if HAS_GPU:
        logger.info(f"GPU detected: {gpus[0].name}, VRAM: {gpus[0].memoryTotal}MB")
    else:
        logger.warning("GPU not detected")
except:
    HAS_GPU = False
    logger.warning("GPU detection failed")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ ChromaDB
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    embedder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    CHROMADB_AVAILABLE = True
    logger.info("‚úÖ ChromaDB and SentenceTransformer initialized")
except Exception as e:
    CHROMADB_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è ChromaDB not available: {e}")

# ==================== –ë–ê–ó–ê –î–ê–ù–ù–´–• ====================
def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    
    c.execute('''CREATE TABLE IF NOT EXISTS conversations
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  user_id TEXT,
                  query TEXT,
                  response TEXT,
                  sources TEXT,
                  model_used TEXT,
                  timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                  rating INTEGER DEFAULT 0)''')
    
    c.execute('''CREATE TABLE IF NOT EXISTS knowledge_base
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  topic TEXT,
                  content TEXT,
                  source TEXT,
                  confidence REAL DEFAULT 0.5,
                  timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    
    conn.commit()
    conn.close()

def save_conversation(query, response, sources, model_used, user_id="default"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –≤ –±–∞–∑—É"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    c.execute("INSERT INTO conversations (user_id, query, response, sources, model_used) VALUES (?, ?, ?, ?, ?)",
              (user_id, query, response, json.dumps(sources), model_used))
    conn.commit()
    conversation_id = c.lastrowid
    conn.close()
    return conversation_id

def get_db_cursor():
    """–ü–æ–ª—É—á–∏—Ç—å –∫—É—Ä—Å–æ—Ä –ë–î"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    return conn.cursor()

def add_knowledge(topic, content, source, confidence=0.8):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –≤ –±–∞–∑—É"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    c.execute("INSERT INTO knowledge_base (topic, content, source, confidence) VALUES (?, ?, ?, ?)",
              (topic, content, source, confidence))
    conn.commit()
    conn.close()

def search_knowledge_base(query):
    """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    c.execute("SELECT topic, content, source, confidence FROM knowledge_base WHERE topic LIKE ? OR content LIKE ? ORDER BY confidence DESC LIMIT 5",
              (f"%{query}%", f"%{query}%"))
    results = c.fetchall()
    conn.close()
    return results

def get_conversation_history(user_id="default", limit=50):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    c.execute("SELECT query, response, timestamp FROM conversations WHERE user_id=? ORDER BY timestamp DESC LIMIT ?",
              (user_id, limit))
    history = c.fetchall()
    conn.close()
    return history

def get_db_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î"""
    conn = sqlite3.connect('/app/data/ii_agent.db')
    c = conn.cursor()
    
    c.execute("SELECT COUNT(*) FROM conversations")
    total_conversations = c.fetchone()[0]
    
    c.execute("SELECT COUNT(*) FROM knowledge_base")
    total_knowledge = c.fetchone()[0]
    
    conn.close()
    
    return {
        "conversations": total_conversations,
        "knowledge_items": total_knowledge
    }

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
init_db()

# ==================== WEB –ü–û–ò–°–ö ====================
def search_web(query, max_results=5):
    """–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ DuckDuckGo"""
    try:
        ddgs = DDGS()
        results = []
        for result in ddgs.text(query, max_results=max_results):
            results.append({
                "title": result.get("title", ""),
                "url": result.get("href", ""),
                "snippet": result.get("body", "")
            })
        return results
    except Exception as e:
        logger.error(f"Web search error: {e}")
        return []

def scrape_url(url):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        response = requests.get(url, timeout=10, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        soup = BeautifulSoup(response.content, 'html.parser')
        
        for script in soup(["script", "style"]):
            script.decompose()
        
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return text[:5000]
    except Exception as e:
        logger.error(f"URL scraping error: {e}")
        return ""

# ==================== OLLAMA –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–ï ====================
def query_ollama(prompt, model="qwen2.5:7b-instruct-q5_K_M", temperature=0.7, max_tokens=2000):
    """–ó–∞–ø—Ä–æ—Å –∫ Ollama LLM"""
    try:
        response = requests.post(
            f"{OLLAMA_API_URL}/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": False
            },
            timeout=MODEL_TIMEOUT
        )
        
        if response.status_code == 200:
            return response.json().get("response", "")
        else:
            logger.error(f"Ollama API error: {response.status_code}")
            return None
            
    except Exception as e:
        logger.error(f"Ollama query error: {e}")
        return None

async def stream_ollama(prompt, model="qwen2.5:7b-instruct-q5_K_M", temperature=0.7):
    """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Ollama"""
    try:
        response = requests.post(
            f"{OLLAMA_API_URL}/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "temperature": temperature,
                "stream": True
            },
            stream=True,
            timeout=MODEL_TIMEOUT
        )
        
        for line in response.iter_lines():
            if line:
                data = json.loads(line)
                if "response" in data:
                    yield data["response"]
                    
    except Exception as e:
        logger.error(f"Ollama streaming error: {e}")
        yield f"Error: {str(e)}"

# ==================== –ê–î–ú–ò–ù–ö–ê API ====================

app = FastAPI(
    title="II-Agent Pro API",
    description="–õ–æ–∫–∞–ª—å–Ω—ã–π AI-–∞–≥–µ–Ω—Ç —Å —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ–º",
    version="5.0"
)


@app.get("/api/admin/models")
async def get_ollama_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π Ollama"""
    try:
        response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=5)
        models_data = response.json()
        models = models_data.get("models", [])
        
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        
        for model in models:
            model_name = model.get("name", "")
            c.execute("SELECT COUNT(*) FROM conversations WHERE model_used = ?", (model_name,))
            usage_count = c.fetchone()[0]
            model["usage_count"] = usage_count
            
        conn.close()
        
        return {"models": models, "status": "success"}
        
    except Exception as e:
        logger.error(f"Error getting models: {e}")
        return {"error": str(e), "models": []}

@app.post("/api/admin/models/pull")
async def pull_ollama_model(request: Request):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å"""
    try:
        data = await request.json()
        model_name = data.get("model")
        
        if not model_name:
            raise HTTPException(status_code=400, detail="Model name required")
        
        response = requests.post(
            f"{OLLAMA_API_URL}/api/pull",
            json={"name": model_name},
            stream=True,
            timeout=3600
        )
        
        async def stream_progress():
            for line in response.iter_lines():
                if line:
                    yield f"data: {line.decode()}\n\n"
                    await asyncio.sleep(0.1)
        
        return StreamingResponse(stream_progress(), media_type="text/event-stream")
        
    except Exception as e:
        logger.error(f"Error pulling model: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)

@app.delete("/api/admin/models/{model_name}")
async def delete_ollama_model(model_name: str):
    """–£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å"""
    try:
        response = requests.delete(
            f"{OLLAMA_API_URL}/api/delete",
            json={"name": model_name},
            timeout=30
        )
        
        if response.status_code == 200:
            return {"status": "success", "message": f"Model {model_name} deleted"}
        else:
            return {"status": "error", "message": f"Failed to delete: {response.text}"}
            
    except Exception as e:
        logger.error(f"Error deleting model: {e}")
        return {"error": str(e)}

@app.get("/api/admin/system/stats")
async def get_system_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        
        ram = psutil.virtual_memory()
        ram_total = ram.total / (1024**3)
        ram_used = ram.used / (1024**3)
        ram_percent = ram.percent
        
        gpu_stats = []
        try:
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                gpu_stats.append({
                    "name": gpu.name,
                    "load": round(gpu.load * 100, 1),
                    "memory_used": gpu.memoryUsed,
                    "memory_total": gpu.memoryTotal,
                    "temperature": gpu.temperature
                })
        except:
            gpu_stats = []
        
        disk = psutil.disk_usage('/app/data')
        disk_total = disk.total / (1024**3)
        disk_used = disk.used / (1024**3)
        disk_percent = disk.percent
        
        return {
            "cpu": {"percent": round(cpu_percent, 1), "count": cpu_count},
            "ram": {"total_gb": round(ram_total, 2), "used_gb": round(ram_used, 2), "percent": round(ram_percent, 1)},
            "gpu": gpu_stats,
            "disk": {"total_gb": round(disk_total, 2), "used_gb": round(disk_used, 2), "percent": round(disk_percent, 1)},
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error getting system stats: {e}")
        return {"error": str(e)}

@app.get("/api/admin/logs")
async def get_logs(level: str = "INFO", limit: int = 100):
    """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        log_file = Path("/app/logs/ii_agent.log")
        
        if not log_file.exists():
            return {"logs": [], "message": "Log file not found"}
        
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        if level != "ALL":
            filtered = [line for line in lines if level in line]
        else:
            filtered = lines
        
        return {"logs": filtered[-limit:], "total": len(filtered), "level": level}
        
    except Exception as e:
        logger.error(f"Error reading logs: {e}")
        return {"error": str(e), "logs": []}

@app.post("/api/admin/settings")
async def update_settings(request: Request):
    """–û–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        settings = await request.json()
        config_file = Path("/app/data/settings.json")
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(settings, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Settings updated: {settings}")
        return {"status": "success", "settings": settings}
        
    except Exception as e:
        logger.error(f"Error updating settings: {e}")
        return {"error": str(e)}

@app.get("/api/admin/settings")
async def get_settings():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"""
    try:
        config_file = Path("/app/data/settings.json")
        
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        default_settings = {
            "default_model": "qwen2.5:7b-instruct-q5_K_M",
            "temperature": 0.7,
            "max_tokens": 2000,
            "rag_top_k": 5,
            "enable_web_search": True,
            "enable_rag": True
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(default_settings, f, indent=2)
        
        return default_settings
        
    except Exception as e:
        logger.error(f"Error loading settings: {e}")
        return {"error": str(e)}

# ==================== WEB SEARCH UNIFIED ====================
def web_search_unified(query: str, max_results: int = 5) -> list:
    """
    Unified web search with Google CSE primary and DuckDuckGo fallback.
    
    Args:
        query: Search query string
        max_results: Maximum number of results to return
        
    Returns:
        List of dicts with keys: url, title, snippet
    """
    results = []
    
    # Try Google Custom Search first
    google_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_CSE_API_KEY")
    google_cx = os.getenv("GOOGLE_CSE_CX") or os.getenv("GOOGLE_CSE_ID")
    
    if google_key and google_cx:
        try:
            logger.info(f"üîç Google CSE search: {query}")
            url = "https://www.googleapis.com/customsearch/v1"
            params = {
                "key": google_key,
                "cx": google_cx,
                "q": query,
                "num": max_results
            }
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            for item in data.get("items", []):
                results.append({
                    "url": item.get("link", ""),
                    "title": item.get("title", ""),
                    "snippet": item.get("snippet", "")
                })
            
            if results:
                logger.info(f"‚úÖ Google CSE: found {len(results)} results")
                return results
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Google CSE failed: {e}, falling back to DuckDuckGo")
    
    # Fallback to DuckDuckGo
    try:
        logger.info(f"üîç DuckDuckGo search: {query}")
        ddg = DDGS()
        ddg_results = ddg.text(query, max_results=max_results)
        
        for item in ddg_results:
            results.append({
                "url": item.get("href", ""),
                "title": item.get("title", ""),
                "snippet": item.get("body", "")
            })
        
        logger.info(f"‚úÖ DuckDuckGo: found {len(results)} results")
        
    except Exception as e:
        logger.error(f"‚ùå DuckDuckGo failed: {e}")
    
    return results


# ==================== FASTAPI –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ====================

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== –û–°–ù–û–í–ù–´–ï ENDPOINTS ====================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "service": "II-Agent Pro API",
        "version": "5.0",
        "status": "running",
        "features": ["chat", "rag", "web_search", "training", "backup", "admin"]
    }

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    try:
        ollama_response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=5)
        ollama_status = "connected" if ollama_response.status_code == 200 else "disconnected"
        
        conn = sqlite3.connect('/app/data/ii_agent.db')
        conn.close()
        db_status = "healthy"
        
        chromadb_status = "available" if CHROMADB_AVAILABLE else "unavailable"
        
        return {
            "status": "healthy",
            "ollama": ollama_status,
            "database": db_status,
            "chromadb": chromadb_status,
            "gpu": "available" if HAS_GPU else "unavailable",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "unhealthy", "error": str(e)}

@app.get("/stats")
async def get_stats():
    """–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        db_stats = get_db_stats()
        
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        c.execute("SELECT model_used, COUNT(*) as count FROM conversations GROUP BY model_used")
        model_usage = {row[0]: row[1] for row in c.fetchall()}
        conn.close()
        
        uptime = time.time() - app.state.start_time if hasattr(app.state, 'start_time') else 0
        
        return {
            "total_conversations": db_stats["conversations"],
            "knowledge_items": db_stats["knowledge_items"],
            "model_usage": model_usage,
            "uptime_seconds": int(uptime),
            "chromadb_available": CHROMADB_AVAILABLE,
            "gpu_available": HAS_GPU
        }
    except Exception as e:
        logger.error(f"Stats error: {e}")
        return {"error": str(e)}

@app.get("/history")
async def get_history(limit: int = 50):
    """–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤"""
    try:
        history = get_conversation_history(limit=limit)
        return {
            "history": [{"query": h[0], "response": h[1], "timestamp": h[2]} for h in history],
            "count": len(history)
        }
    except Exception as e:
        logger.error(f"History error: {e}")
        return {"error": str(e)}

# ==================== –ß–ê–¢ ENDPOINTS ====================

@app.post("/chat")
async def chat(request: Request):
    """–û—Å–Ω–æ–≤–Ω–æ–π —á–∞—Ç endpoint"""
    try:
        data = await request.json()
        query = data.get("query", "")
        use_rag = data.get("use_rag", True)
        use_web = data.get("use_web", False)
        model = data.get("model", "qwen2.5:7b-instruct-q5_K_M")
        
        if not query:
            raise HTTPException(status_code=400, detail="Query required")
        
        logger.info(f"Chat query: {query[:100]}...")
        
        context_parts = []
        sources = []
        
        if use_rag and CHROMADB_AVAILABLE:
            try:
                rag_results = search_knowledge_base(query)
                if rag_results:
                    context_parts.append("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:")
                    for topic, content, source, confidence in rag_results[:3]:
                        context_parts.append(f"- {content[:200]}")
                        sources.append({"type": "rag", "source": source, "confidence": confidence})
            except Exception as e:
                logger.error(f"RAG search error: {e}")
        
        if use_web:
            try:
                web_results = search_web(query, max_results=3)
                if web_results:
                    context_parts.append("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞:")
                    for result in web_results:
                        context_parts.append(f"- {result['title']}: {result['snippet'][:150]}")
                        sources.append({"type": "web", "title": result['title'], "url": result['url']})
            except Exception as e:
                logger.error(f"Web search error: {e}")
        
        context = "\n".join(context_parts) if context_parts else ""
        
        full_prompt = f"""–¢—ã - —É–º–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–¢–≤–æ–π –æ—Ç–≤–µ—Ç:"""
        
        response = query_ollama(full_prompt, model=model)
        
        if response is None:
            raise HTTPException(status_code=500, detail="LLM query failed")
        
        conversation_id = save_conversation(query, response, sources, model)
        
        return {
            "response": response,
            "sources": sources,
            "model": model,
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat/stream")
async def chat_stream(request: Request):
    """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞"""
    try:
        data = await request.json()
        query = data.get("query", "")
        model = data.get("model", "qwen2.5:7b-instruct-q5_K_M")
        
        if not query:
            raise HTTPException(status_code=400, detail="Query required")
        
        async def generate():
            full_response = ""
            async for chunk in stream_ollama(query, model=model):
                full_response += chunk
                yield f"data: {json.dumps({'chunk': chunk})}\n\n"
            
            save_conversation(query, full_response, [], model)
            yield f"data: {json.dumps({'done': True})}\n\n"
        
        return StreamingResponse(generate(), media_type="text/event-stream")
        
    except Exception as e:
        logger.error(f"Stream chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
# ==================== RAG ENDPOINTS ====================

@app.post("/rag/add")
async def add_rag_item(request: Request):
    """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    try:
        data = await request.json()
        topic = data.get("topic", "")
        content = data.get("content", "")
        source = data.get("source", "manual")
        confidence = data.get("confidence", 0.8)
        
        if not topic or not content:
            raise HTTPException(status_code=400, detail="Topic and content required")
        
        add_knowledge(topic, content, source, confidence)
        
        return {"status": "success", "message": "Knowledge added", "topic": topic}
        
    except Exception as e:
        logger.error(f"RAG add error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/rag/search")
async def search_rag(query: str, limit: int = 5):
    """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
    try:
        results = search_knowledge_base(query)
        
        return {
            "query": query,
            "results": [
                {"topic": r[0], "content": r[1], "source": r[2], "confidence": r[3]}
                for r in results[:limit]
            ],
            "count": len(results)
        }
        
    except Exception as e:
        logger.error(f"RAG search error: {e}")
        return {"error": str(e)}

@app.get("/rag/stats")
async def rag_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG"""
    try:
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        
        c.execute("SELECT COUNT(*) FROM knowledge_base")
        total = c.fetchone()[0]
        
        c.execute("SELECT source, COUNT(*) as count FROM knowledge_base GROUP BY source")
        by_source = {row[0]: row[1] for row in c.fetchall()}
        
        c.execute("SELECT AVG(confidence) FROM knowledge_base")
        avg_confidence = c.fetchone()[0] or 0.0
        
        conn.close()
        
        return {
            "total_items": total,
            "by_source": by_source,
            "avg_confidence": round(avg_confidence, 2),
            "chromadb_available": CHROMADB_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"RAG stats error: {e}")
        return {"error": str(e)}

# ==================== TRAINING ENDPOINTS ====================

training_status = {
    "is_running": False,
    "progress": 0,
    "current_source": None,
    "items_processed": 0,
    "start_time": None
}

@app.post("/training/start")
async def start_training(request: Request):
    """–ó–∞–ø—É—Å–∫ –Ω–æ—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    global training_status
    
    try:
        if training_status["is_running"]:
            return {"status": "error", "message": "Training already running"}
        
        data = await request.json()
        duration_hours = data.get("duration_hours", 4)
        cycles_per_hour = data.get("cycles_per_hour", 4)
        sources = data.get("sources", ["wikipedia", "github", "habr"])
        
        asyncio.create_task(run_training(duration_hours, cycles_per_hour, sources))
        
        return {
            "status": "started",
            "duration_hours": duration_hours,
            "cycles_per_hour": cycles_per_hour,
            "sources": sources
        }
        
    except Exception as e:
        logger.error(f"Training start error: {e}")
        return {"error": str(e)}

async def run_training(duration_hours, cycles_per_hour, sources):
    """–§–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ"""
    global training_status
    
    training_status["is_running"] = True
    training_status["progress"] = 0
    training_status["start_time"] = datetime.now().isoformat()
    
    try:
        total_cycles = duration_hours * cycles_per_hour
        
        for cycle in range(total_cycles):
            source = sources[cycle % len(sources)]
            training_status["current_source"] = source
            training_status["progress"] = int((cycle / total_cycles) * 100)
            
            if source == "wikipedia":
                await train_from_wikipedia()
            elif source == "github":
                await train_from_github()
            elif source == "habr":
                await train_from_habr()
            
            training_status["items_processed"] += 1
            
            await asyncio.sleep(60 * 60 / cycles_per_hour)
        
        training_status["progress"] = 100
        logger.info(f"Training completed: {training_status['items_processed']} items")
        
    except Exception as e:
        logger.error(f"Training error: {e}")
    finally:
        training_status["is_running"] = False

async def train_from_wikipedia():
    """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ Wikipedia"""
    try:
        topics = ["Python", "Artificial Intelligence", "Machine Learning", "Neural Network"]
        topic = topics[training_status["items_processed"] % len(topics)]
        
        page = wikipedia.page(topic, auto_suggest=True)
        content = page.content[:1000]
        
        add_knowledge(topic, content, f"wikipedia:{page.url}", confidence=0.9)
        logger.info(f"Added Wikipedia article: {topic}")
        
    except Exception as e:
        logger.error(f"Wikipedia training error: {e}")

async def train_from_github():
    """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ GitHub (–∑–∞–≥–ª—É—à–∫–∞)"""
    logger.info("GitHub training (placeholder)")
    pass

async def train_from_habr():
    """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ Habr (–∑–∞–≥–ª—É—à–∫–∞)"""
    logger.info("Habr training (placeholder)")
    pass

@app.get("/training/status")
async def get_training_status():
    """–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è"""
    return training_status

@app.post("/training/stop")
async def stop_training():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    global training_status
    training_status["is_running"] = False
    return {"status": "stopped"}

# ==================== BACKUP ENDPOINTS ====================

@app.post("/backup/create")
async def create_backup_endpoint(request: Request):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞"""
    try:
        data = await request.json()
        description = data.get("description", "Manual backup")
        
        result = backup_system.create_backup(description)
        
        return {
            "status": "success",
            "backup_id": result.get("commit_hash", "unknown"),
            "description": description,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Backup creation error: {e}")
        return {"error": str(e)}

@app.get("/backup/list")
async def list_backups():
    """–°–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤"""
    try:
        backups = backup_system.list_backups()
        return {"backups": backups, "count": len(backups)}
    except Exception as e:
        logger.error(f"Backup list error: {e}")
        return {"error": str(e)}

@app.post("/backup/restore")
async def restore_backup(request: Request):
    """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞"""
    try:
        data = await request.json()
        backup_id = data.get("backup_id")
        
        if not backup_id:
            raise HTTPException(status_code=400, detail="backup_id required")
        
        result = backup_system.restore_backup(backup_id)
        
        return {"status": "success", "backup_id": backup_id, "message": "Backup restored"}
        
    except Exception as e:
        logger.error(f"Backup restore error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== TEST ENDPOINTS ====================

@app.get("/test/run")
async def run_tests():
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤"""
    try:
        results = test_system.run_all_tests()
        return {
            "test_results": results,
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.get("status") == "passed"),
            "failed": sum(1 for r in results if r.get("status") == "failed")
        }
    except Exception as e:
        logger.error(f"Test error: {e}")
        return {"error": str(e)}

# ==================== WEBSOCKET ====================

@app.websocket("/ws/chat")
async def websocket_chat(websocket: WebSocket):
    """WebSocket –¥–ª—è —á–∞—Ç–∞"""
    await websocket.accept()
    logger.info("WebSocket chat connected")
    
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            query = message.get("query", "")
            model = message.get("model", "qwen2.5:7b-instruct-q5_K_M")
            
            if not query:
                await websocket.send_json({"error": "Query required"})
                continue
            
            full_response = ""
            async for chunk in stream_ollama(query, model=model):
                full_response += chunk
                await websocket.send_json({"type": "chunk", "content": chunk})
            
            await websocket.send_json({"type": "done", "full_response": full_response})
            
            save_conversation(query, full_response, [], model)
            
    except WebSocketDisconnect:
        logger.info("WebSocket chat disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        try:
            await websocket.send_json({"error": str(e)})
        except:
            pass

@app.websocket("/ws/self-healing")
async def websocket_self_healing(websocket: WebSocket):
    """WebSocket –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ self-healing"""
    await websocket.accept()
    logger.info("WebSocket self-healing connected")
    
    try:
        while True:
            status = {
                "timestamp": datetime.now().isoformat(),
                "status": "healthy",
                "last_check": "OK",
                "auto_fixes": 0,
                "system_load": psutil.cpu_percent()
            }
            await websocket.send_json(status)
            await asyncio.sleep(5)
            
    except WebSocketDisconnect:
        logger.info("WebSocket self-healing disconnected")
    except Exception as e:
        logger.error(f"WebSocket self-healing error: {e}")

# ==================== WEB SEARCH ENDPOINTS ====================

@app.get("/search/web")
async def web_search_endpoint(query: str, max_results: int = 5):
    """–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
    try:
        results = search_web(query, max_results=max_results)
        return {"query": query, "results": results, "count": len(results)}
    except Exception as e:
        logger.error(f"Web search endpoint error: {e}")
        return {"error": str(e)}

@app.post("/search/scrape")
async def scrape_endpoint(request: Request):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å URL"""
    try:
        data = await request.json()
        url = data.get("url")
        
        if not url:
            raise HTTPException(status_code=400, detail="URL required")
        
        text = scrape_url(url)
        
        return {"url": url, "text": text, "length": len(text)}
        
    except Exception as e:
        logger.error(f"Scrape error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== –ê–õ–ò–ê–°–´ –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 404) ====================

@app.post("/ask")
async def ask_alias(request: Request):
    """–ê–ª–∏–∞—Å –¥–ª—è /chat"""
    return await chat(request)

@app.get("/api/status")
async def status_alias():
    """–ê–ª–∏–∞—Å –¥–ª—è /stats"""
    return await get_stats()

@app.get("/api/rag/stats")
async def rag_stats_alias():
    """–ê–ª–∏–∞—Å –¥–ª—è /rag/stats"""
    return await rag_stats()

@app.get("/api/training/status")
async def training_status_alias():
    """–ê–ª–∏–∞—Å –¥–ª—è /training/status"""
    return await get_training_status()

@app.post("/api/training/start")
async def training_start_alias(request: Request):
    """–ê–ª–∏–∞—Å –¥–ª—è /training/start"""
    return await start_training(request)

@app.get("/api/model/stats")
async def model_stats_alias():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π"""
    try:
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        c.execute("SELECT model_used, COUNT(*) as count FROM conversations GROUP BY model_used")
        stats = {row[0]: row[1] for row in c.fetchall()}
        conn.close()
        
        return {"model_usage": stats, "total": sum(stats.values())}
    except Exception as e:
        logger.error(f"Model stats error: {e}")
        return {"error": str(e)}

@app.get("/api/expert/requests")
async def expert_requests_alias():
    """–ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–º –º–æ–¥–µ–ª—è–º"""
    try:
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        c.execute("""
            SELECT id, query, model_used, timestamp, rating 
            FROM conversations 
            WHERE model_used LIKE '%expert%' OR model_used LIKE '%32b%'
            ORDER BY timestamp DESC 
            LIMIT 50
        """)
        
        results = []
        for row in c.fetchall():
            results.append({
                "id": row[0],
                "query": row[1],
                "model": row[2],
                "timestamp": row[3],
                "rating": row[4],
                "status": "completed"
            })
        
        conn.close()
        return {"requests": results, "total": len(results)}
    except Exception as e:
        logger.error(f"Expert requests error: {e}")
        return {"error": str(e)}

# ==================== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï ENDPOINTS ====================

@app.post("/models/switch")
async def switch_model(request: Request):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
    try:
        data = await request.json()
        model = data.get("model")
        
        if not model:
            raise HTTPException(status_code=400, detail="Model name required")
        
        response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=5)
        models = response.json().get("models", [])
        model_names = [m["name"] for m in models]
        
        if model not in model_names:
            raise HTTPException(status_code=404, detail=f"Model {model} not found")
        
        settings = await get_settings()
        settings["default_model"] = model
        
        config_file = Path("/app/data/settings.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(settings, f, indent=2)
        
        return {"status": "success", "model": model, "message": f"Default model switched to {model}"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Model switch error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/conversation/rate")
async def rate_conversation(request: Request):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞"""
    try:
        data = await request.json()
        conversation_id = data.get("conversation_id")
        rating = data.get("rating")
        
        if not conversation_id or rating is None:
            raise HTTPException(status_code=400, detail="conversation_id and rating required")
        
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        c.execute("UPDATE conversations SET rating = ? WHERE id = ?", (rating, conversation_id))
        conn.commit()
        conn.close()
        
        return {"status": "success", "conversation_id": conversation_id, "rating": rating}
        
    except Exception as e:
        logger.error(f"Rating error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/knowledge/bulk-add")
async def bulk_add_knowledge(request: Request):
    """–ú–∞—Å—Å–æ–≤–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π"""
    try:
        data = await request.json()
        items = data.get("items", [])
        
        if not items:
            raise HTTPException(status_code=400, detail="Items required")
        
        conn = sqlite3.connect('/app/data/ii_agent.db')
        c = conn.cursor()
        
        for item in items:
            topic = item.get("topic")
            content = item.get("content")
            source = item.get("source", "bulk_import")
            confidence = item.get("confidence", 0.7)
            
            if topic and content:
                c.execute(
                    "INSERT INTO knowledge_base (topic, content, source, confidence) VALUES (?, ?, ?, ?)",
                    (topic, content, source, confidence)
                )
        
        conn.commit()
        conn.close()
        
        return {"status": "success", "items_added": len(items)}
        
    except Exception as e:
        logger.error(f"Bulk add error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/disk-usage")
async def get_disk_usage():
    """–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º"""
    try:
        data_dir = Path("/app/data")
        
        usage = {}
        for item in data_dir.iterdir():
            if item.is_dir():
                size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())
                usage[item.name] = {
                    "size_bytes": size,
                    "size_mb": round(size / (1024**2), 2),
                    "size_gb": round(size / (1024**3), 2)
                }
            elif item.is_file():
                size = item.stat().st_size
                usage[item.name] = {
                    "size_bytes": size,
                    "size_mb": round(size / (1024**2), 2)
                }
        
        return {
            "usage": usage,
            "total_mb": round(sum(u["size_bytes"] for u in usage.values()) / (1024**2), 2)
        }
        
    except Exception as e:
        logger.error(f"Disk usage error: {e}")
        return {"error": str(e)}

# ==================== STARTUP & SHUTDOWN ====================

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    logger.info("=" * 50)
    logger.info("üöÄ II-Agent Pro v5.0 Starting...")
    logger.info("=" * 50)
    
    app.state.start_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama
    try:
        response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            logger.info(f"‚úÖ Ollama connected: {len(models)} models available")
        else:
            logger.warning("‚ö†Ô∏è Ollama not responding")
    except Exception as e:
        logger.error(f"‚ùå Ollama connection failed: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
    try:
        conn = sqlite3.connect('/app/data/ii_agent.db')
        conn.close()
        logger.info("‚úÖ Database connected")
    except Exception as e:
        logger.error(f"‚ùå Database error: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ChromaDB
    if CHROMADB_AVAILABLE:
        logger.info("‚úÖ ChromaDB available")
    else:
        logger.warning("‚ö†Ô∏è ChromaDB not available")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    if HAS_GPU:
        logger.info("‚úÖ GPU detected")
    else:
        logger.warning("‚ö†Ô∏è No GPU detected")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º
    try:
        backup_system
        logger.info("‚úÖ Backup system initialized")
    except Exception as e:
        logger.error(f"‚ùå Backup system error: {e}")
    
    try:
        test_system
        logger.info("‚úÖ Test system initialized")
    except Exception as e:
        logger.error(f"‚ùå Test system error: {e}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ AGENT_INSTRUCTIONS.md
    try:
        instructions_path = Path("/app/AGENT_INSTRUCTIONS.md")
        if instructions_path.exists():
            with open(instructions_path, 'r', encoding='utf-8') as f:
                instructions = f.read()
            add_knowledge(
                "Agent Instructions",
                instructions,
                "agent_instructions",
                confidence=1.0
            )
            logger.info("‚úÖ Agent instructions loaded")
        else:
            logger.warning("‚ö†Ô∏è AGENT_INSTRUCTIONS.md not found")
    except Exception as e:
        logger.error(f"‚ùå Agent instructions error: {e}")
    
    logger.info("=" * 50)
    logger.info("‚úÖ II-Agent Pro ready!")
    logger.info("=" * 50)

@app.on_event("shutdown")
async def shutdown_event():
    """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
    logger.info("üõë II-Agent Pro shutting down...")
    
    if training_status["is_running"]:
        training_status["is_running"] = False
        logger.info("‚èπÔ∏è Training stopped")
    
    try:
        backup_system.create_backup("Automatic shutdown backup")
        logger.info("üíæ Final backup created")
    except Exception as e:
        logger.error(f"‚ùå Final backup error: {e}")
    
    logger.info("üëã Goodbye!")

# ==================== –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê ====================

if __name__ == "__main__":
    import uvicorn
    
    Path("/app/data").mkdir(parents=True, exist_ok=True)
    Path("/app/logs").mkdir(parents=True, exist_ok=True)
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True,
        workers=1
    )

