# -*- coding: utf-8 -*-
"""
II-Agent Self-Improvement System
–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∏ —Å–∞–º–æ–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
"""
import os
import re
import json
import logging
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

CODE_DIR = Path("/app")
BACKUP_DIR = Path("/app/backups")
LOGS_FILE = Path("/app/logs/agent.log")

BACKUP_DIR.mkdir(parents=True, exist_ok=True)

# ==================== –í–´–ó–û–í LLM ====================

def call_llm_for_analysis(prompt: str) -> str:
    """–í—ã–∑–æ–≤ LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º"""
    try:
        import requests
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "qwen2.5:7b",
                "prompt": prompt,
                "stream": False
            },
            timeout=60
        )
        
        if response.status_code == 200:
            return response.json().get('response', '')
        else:
            logger.error(f"LLM call failed: {response.status_code}")
            return ""
            
    except Exception as e:
        logger.error(f"LLM analysis error: {e}")
        return ""

# ==================== –ê–ù–ê–õ–ò–ó –õ–û–ì–û–í ====================

def analyze_logs(hours: int = 1) -> List[Dict[str, Any]]:
    """–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–æ–≥–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–±–ª–µ–º"""
    try:
        if not LOGS_FILE.exists():
            logger.warning("Log file not found")
            return []
        
        # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫
        with open(LOGS_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()[-1000:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å—Ç—Ä–æ–∫
        
        issues = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
        error_patterns = {
            'timeout': r'Timeout|—Ç–∞–π–º–∞—É—Ç',
            'empty_response': r'–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç|Empty response',
            'no_info': r'–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç|–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',
            'model_error': r'Model error|–ú–æ–¥–µ–ª—å.*–æ—à–∏–±–∫',
            'parse_error': r'Parse error|–ø–∞—Ä—Å–∏–Ω–≥.*–æ—à–∏–±–∫',
            'api_error': r'API error|API.*–æ—à–∏–±–∫',
            'connection_error': r'Connection.*error|—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.*–æ—à–∏–±–∫',
            'memory_error': r'Memory.*error|–ø–∞–º—è—Ç.*–æ—à–∏–±–∫'
        }
        
        for line in lines:
            for error_type, pattern in error_patterns.items():
                if re.search(pattern, line, re.I):
                    issues.append({
                        'type': error_type,
                        'line': line.strip(),
                        'timestamp': datetime.now().isoformat()
                    })
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
        grouped = {}
        for issue in issues:
            error_type = issue['type']
            if error_type not in grouped:
                grouped[error_type] = []
            grouped[error_type].append(issue)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
        report = []
        for error_type, errors in grouped.items():
            if len(errors) > 3:  # –¢–æ–ª—å–∫–æ —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏
                report.append({
                    'type': error_type,
                    'count': len(errors),
                    'severity': 'high' if len(errors) > 10 else 'medium',
                    'sample': errors[-1]['line']
                })
        
        return report
        
    except Exception as e:
        logger.error(f"Log analysis error: {e}")
        return []

# ==================== –ß–¢–ï–ù–ò–ï –ö–û–î–ê ====================

def read_code_file(filename: str = "main.py") -> Optional[Dict[str, Any]]:
    """–ß—Ç–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞"""
    try:
        filepath = CODE_DIR / filename
        
        if not filepath.exists():
            return None
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–∏
        functions = {}
        current_func = None
        func_lines = []
        
        for line in content.split('\n'):
            if line.startswith('def ') or line.startswith('async def '):
                if current_func:
                    functions[current_func] = '\n'.join(func_lines)
                match = re.match(r'(?:async\s+)?def\s+(\w+)\s*\(', line)
                if match:
                    current_func = match.group(1)
                    func_lines = [line]
            elif current_func:
                func_lines.append(line)
        
        if current_func:
            functions[current_func] = '\n'.join(func_lines)
        
        return {
            'full_code': content,
            'functions': functions,
            'lines': len(content.split('\n'))
        }
        
    except Exception as e:
        logger.error(f"Code reading error: {e}")
        return None

# ==================== LLM –ê–ù–ê–õ–ò–ó –ö–û–î–ê ====================

def analyze_issue_with_llm(issue: Dict[str, Any], code_context: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º—ã —á–µ—Ä–µ–∑ LLM"""
    try:
        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Python –∏ –æ—Ç–ª–∞–¥–∫–µ –∫–æ–¥–∞.

–ü—Ä–æ–±–ª–µ–º–∞: {issue['type']} (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {issue['count']} —Ä–∞–∑)
–£—Ä–æ–≤–µ–Ω—å: {issue['severity']}
–ü—Ä–∏–º–µ—Ä: {issue['sample']}

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥–∞:
{code_context[:2000]} # –ü–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤

–ó–∞–¥–∞—á–∞:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –ø—Ä–∏—á–∏–Ω—É –ø—Ä–æ–±–ª–µ–º—ã
2. –ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
3. –ù–∞–ø–∏—à–∏ —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–ü–†–ò–ß–ò–ù–ê: <–æ–ø–∏—Å–∞–Ω–∏–µ>
–†–ï–®–ï–ù–ò–ï: <–æ–ø–∏—Å–∞–Ω–∏–µ>
–ö–û–î: <–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥>
"""
        
        llm_response = call_llm_for_analysis(prompt)
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç LLM
        cause = ""
        solution = ""
        code = ""
        
        if "–ü–†–ò–ß–ò–ù–ê:" in llm_response:
            cause = llm_response.split("–ü–†–ò–ß–ò–ù–ê:")[1].split("–†–ï–®–ï–ù–ò–ï:")[0].strip()
        if "–†–ï–®–ï–ù–ò–ï:" in llm_response:
            solution = llm_response.split("–†–ï–®–ï–ù–ò–ï:")[1].split("–ö–û–î:")[0].strip()
        if "–ö–û–î:" in llm_response:
            code = llm_response.split("–ö–û–î:")[1].strip()
        
        return {
            'llm_analysis': True,
            'cause': cause,
            'solution': solution,
            'suggested_code': code
        }
        
    except Exception as e:
        logger.error(f"LLM analysis error: {e}")
        return {'llm_analysis': False, 'error': str(e)}

# ==================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô ====================

def generate_fix_for_issue(issue: Dict[str, Any], code_context: Dict[str, Any]) -> Dict[str, Any]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–±–ª–µ–º—ã"""
    
    # –ë–∞–∑–æ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ —à–∞–±–ª–æ–Ω—É
    template_fixes = {
        'timeout': {
            'description': '–ß–∞—Å—Ç—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –º–æ–¥–µ–ª–∏',
            'suggestions': [
                '–£–≤–µ–ª–∏—á–∏—Ç—å timeout –≤ call_model() –¥–æ 180 —Å–µ–∫—É–Ω–¥',
                '–î–æ–±–∞–≤–∏—Ç—å retry –º–µ—Ö–∞–Ω–∏–∑–º',
                '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é'
            ],
            'code_changes': {
                'file': 'main.py',
                'function': 'call_model',
                'change': 'timeout parameter: 120 -> 180'
            }
        },
        'empty_response': {
            'description': '–ú–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã',
            'suggestions': [
                '–£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏',
                '–î–æ–±–∞–≤–∏—Ç—å fallback –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å',
                '–£–≤–µ–ª–∏—á–∏—Ç—å max_tokens'
            ]
        },
        'no_info': {
            'description': '–ú–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"',
            'suggestions': [
                '–°–º—è–≥—á–∏—Ç—å –ø—Ä–æ–º–ø—Ç',
                '–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤',
                '–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤'
            ]
        },
        'model_error': {
            'description': '–û—à–∏–±–∫–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥–µ–ª–∏',
            'suggestions': [
                '–î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫',
                '–£–ª—É—á—à–∏—Ç—å retry –ª–æ–≥–∏–∫—É',
                '–î–æ–±–∞–≤–∏—Ç—å fallback –º–æ–¥–µ–ª—å'
            ]
        },
        'parse_error': {
            'description': '–û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–æ–≤',
            'suggestions': [
                '–£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ HTML',
                '–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–π',
                '–£–≤–µ–ª–∏—á–∏—Ç—å timeout –ø–∞—Ä—Å–∏–Ω–≥–∞'
            ]
        },
        'api_error': {
            'description': '–û—à–∏–±–∫–∏ –≤–Ω–µ—à–Ω–∏—Ö API',
            'suggestions': [
                '–î–æ–±–∞–≤–∏—Ç—å retry —Å exponential backoff',
                '–£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É rate limits',
                '–î–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'
            ]
        },
        'connection_error': {
            'description': '–û—à–∏–±–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è',
            'suggestions': [
                '–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º',
                '–£–≤–µ–ª–∏—á–∏—Ç—å timeout –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π',
                '–î–æ–±–∞–≤–∏—Ç—å offline —Ä–µ–∂–∏–º'
            ]
        },
        'memory_error': {
            'description': '–ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é',
            'suggestions': [
                '–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö',
                '–î–æ–±–∞–≤–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –∫—ç—à–∞',
                '–£–º–µ–Ω—å—à–∏—Ç—å batch size'
            ]
        }
    }
    
    base_fix = template_fixes.get(issue['type'], {
        'description': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞: {issue['type']}",
        'suggestions': ['–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑']
    })
    
    # –î–æ–±–∞–≤–ª—è–µ–º LLM –∞–Ω–∞–ª–∏–∑
    relevant_code = ""
    if code_context and 'functions' in code_context:
        # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        for func_name, func_code in code_context['functions'].items():
            if issue['type'] in func_name.lower():
                relevant_code = func_code
                break
        
        if not relevant_code and code_context['functions']:
            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
            relevant_code = list(code_context['functions'].values())[0]
    
    llm_analysis = analyze_issue_with_llm(issue, relevant_code)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    return {
        **base_fix,
        **llm_analysis,
        'issue_type': issue['type'],
        'count': issue['count'],
        'severity': issue['severity']
    }

# ==================== –°–û–ó–î–ê–ù–ò–ï –ü–ê–¢–ß–ê ====================

def create_patch(fix: Dict[str, Any], code_data: Dict[str, Any]) -> Optional[str]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—á–∞ –¥–ª—è –∫–æ–¥–∞"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        patch_file = BACKUP_DIR / f"patch_{timestamp}.json"
        
        patch = {
            'timestamp': timestamp,
            'created_at': datetime.now().isoformat(),
            'issue_type': fix.get('issue_type', 'unknown'),
            'description': fix['description'],
            'suggestions': fix['suggestions'],
            'llm_analysis': fix.get('llm_analysis', False),
            'llm_cause': fix.get('cause', ''),
            'llm_solution': fix.get('solution', ''),
            'suggested_code': fix.get('suggested_code', ''),
            'changes': fix.get('code_changes', {}),
            'status': 'pending',
            'severity': fix.get('severity', 'medium')
        }
        
        with open(patch_file, 'w', encoding='utf-8') as f:
            json.dump(patch, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Patch created: {patch_file}")
        return str(patch_file)
        
    except Exception as e:
        logger.error(f"Patch creation error: {e}")
        return None

# ==================== –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –ü–ê–¢–ß–ê ====================

def apply_patch(patch_file: Path, auto_approve: bool = False) -> bool:
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ç—á–∞ –∫ –∫–æ–¥—É"""
    try:
        with open(patch_file, 'r', encoding='utf-8') as f:
            patch = json.load(f)
        
        if not auto_approve and patch.get('severity') == 'high':
            logger.warning(f"High severity patch requires manual approval: {patch_file}")
            return False
        
        # –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø
        timestamp = patch.get('timestamp', datetime.now().strftime('%Y%m%d_%H%M%S'))
        backup_file = BACKUP_DIR / f"main_backup_{timestamp}.py"
        original_file = CODE_DIR / "main.py"
        
        if not original_file.exists():
            logger.error("main.py not found")
            return False
        
        with open(original_file, 'r', encoding='utf-8') as f:
            original_code = f.read()
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(original_code)
        
        logger.info(f"Backup created: {backup_file}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å suggested_code
        if patch.get('suggested_code'):
            function_name = patch.get('changes', {}).get('function')
            if function_name:
                # –ù–∞—Ö–æ–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é –∏ –∑–∞–º–µ–Ω—è–µ–º
                new_code = re.sub(
                    rf'def {function_name}\([^)]*\):.*?(?=\ndef |\nclass |\Z)',
                    patch['suggested_code'],
                    original_code,
                    flags=re.DOTALL
                )
                
                with open(original_file, 'w', encoding='utf-8') as f:
                    f.write(new_code)
                
                logger.info(f"‚úÖ Code modified: {function_name}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–∞—Ç—á–∞
        patch['status'] = 'applied'
        patch['applied_at'] = datetime.now().isoformat()
        
        with open(patch_file, 'w', encoding='utf-8') as f:
            json.dump(patch, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ Patch applied: {patch_file}")
        return True
        
    except Exception as e:
        logger.error(f"Patch application error: {e}")
        return False

# ==================== –ú–ï–¢–†–ò–ö–ò ====================

def track_improvement_metrics() -> Dict[str, Any]:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —É–ª—É—á—à–µ–Ω–∏—è"""
    try:
        metrics = {
            'patches_created': 0,
            'patches_applied': 0,
            'patches_pending': 0,
            'errors_by_type': {},
            'last_self_diagnosis': None
        }
        
        if not BACKUP_DIR.exists():
            return metrics
        
        for patch_file in BACKUP_DIR.glob("patch_*.json"):
            try:
                with open(patch_file, 'r') as f:
                    patch = json.load(f)
                
                metrics['patches_created'] += 1
                
                if patch.get('status') == 'applied':
                    metrics['patches_applied'] += 1
                elif patch.get('status') == 'pending':
                    metrics['patches_pending'] += 1
                
                issue_type = patch.get('issue_type', 'unknown')
                if issue_type not in metrics['errors_by_type']:
                    metrics['errors_by_type'][issue_type] = 0
                metrics['errors_by_type'][issue_type] += 1
                
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
                created_at = patch.get('created_at')
                if created_at:
                    if not metrics['last_self_diagnosis'] or created_at > metrics['last_self_diagnosis']:
                        metrics['last_self_diagnosis'] = created_at
                        
            except Exception as e:
                logger.error(f"Error reading patch {patch_file.name}: {e}")
        
        return metrics
        
    except Exception as e:
        logger.error(f"Metrics tracking error: {e}")
        return {}

# ==================== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================

def self_diagnose() -> Dict[str, Any]:
    """–ü–æ–ª–Ω–∞—è —Å–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–∞"""
    try:
        logger.info("=== SELF-DIAGNOSIS STARTED ===")
        
        # 1. –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤
        logger.info("Step 1: Analyzing logs...")
        issues = analyze_logs(hours=1)
        
        if not issues:
            logger.info("‚úÖ No critical issues found")
            return {
                'status': 'healthy',
                'issues': [],
                'suggestions': [],
                'metrics': track_improvement_metrics()
            }
        
        logger.info(f"‚ö†Ô∏è Found {len(issues)} issue types")
        
        # 2. –ß—Ç–µ–Ω–∏–µ –∫–æ–¥–∞
        logger.info("Step 2: Reading code...")
        code_data = read_code_file("main.py")
        
        if not code_data:
            logger.error("‚ùå Cannot read code")
            return {'status': 'error', 'message': 'Cannot read code'}
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π (—Å LLM)
        logger.info("Step 3: Generating fixes with LLM...")
        fixes = []
        
        for issue in issues:
            logger.info(f"Analyzing {issue['type']} with LLM...")
            fix = generate_fix_for_issue(issue, code_data)
            fixes.append(fix)
        
        # 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—á–µ–π
        logger.info("Step 4: Creating patches...")
        patches = []
        
        for fix in fixes:
            patch_file = create_patch(fix, code_data)
            if patch_file:
                patches.append(patch_file)
        
        logger.info(f"=== SELF-DIAGNOSIS COMPLETED: {len(patches)} patches created ===")
        
        return {
            'status': 'issues_found',
            'issues_count': len(issues),
            'fixes': fixes,
            'patches': patches,
            'code_health': {
                'total_lines': code_data['lines'],
                'total_functions': len(code_data['functions'])
            },
            'metrics': track_improvement_metrics()
        }
        
    except Exception as e:
        logger.error(f"Self-diagnosis error: {e}")
        return {'status': 'error', 'message': str(e)}

# ==================== –°–ü–ò–°–û–ö –ü–ê–¢–ß–ï–ô ====================

def list_patches() -> List[Dict[str, Any]]:
    """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞—Ç—á–µ–π"""
    patches = []
    if BACKUP_DIR.exists():
        for patch_file in BACKUP_DIR.glob("patch_*.json"):
            try:
                with open(patch_file, 'r', encoding='utf-8') as f:
                    patch = json.load(f)
                patch['filename'] = patch_file.name
                patches.append(patch)
            except Exception as e:
                logger.error(f"Error reading patch {patch_file.name}: {e}")
    
    patches.sort(key=lambda x: x.get('created_at', ''), reverse=True)
    return patches

def get_patch(patch_filename: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ç—á –ø–æ –∏–º–µ–Ω–∏"""
    patch_file = BACKUP_DIR / patch_filename
    if patch_file.exists():
        try:
            with open(patch_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error reading patch {patch_filename}: {e}")
    return None

# ==================== –ê–í–¢–û–£–°–¢–ê–ù–û–í–ö–ê –ü–ê–ö–ï–¢–û–í ====================

def auto_install_package(package_name: str) -> Dict[str, Any]:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –ø–∞–∫–µ—Ç–∞"""
    try:
        logger.info(f"üì¶ Installing package: {package_name}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        if not re.match(r'^[a-zA-Z0-9_-]+$', package_name):
            return {"success": False, "error": "Invalid package name"}
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install", package_name],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode == 0:
            logger.info(f"‚úÖ Package {package_name} installed")
            return {"success": True, "output": result.stdout}
        else:
            logger.error(f"‚ùå Package {package_name} installation failed")
            return {"success": False, "error": result.stderr}
            
    except Exception as e:
        logger.error(f"Installation error: {e}")
        return {"success": False, "error": str(e)}
